# Loader
loader.id=0

#currently, this is disabled.
loader.lifetime=50000

#number of threads running in the loader
loader.parallelism=8

#how many puller threads running in parallel?
#partitions will be distributed to all threads equally.
puller.parallelism=4

#this is used in DataPuller.
#each partition buffer can hold a maximum number of messages.
#if capacity reached, they will be a SortedBuffer and compacted later.
sortedBuffer.capacity=5000

#this is the number of SortedBuffer in the blocking queue.
#the blocking queue is consumed by DataCompactor.
sorterCompactor.capacity=50

#capacity of SegmentContainer.
#when capacity reached, OFF_HEAP segments are flushed into disks.
container.capacity=1
flushing.capacity=1

#this is used to control the number of records inside a segment
compactor.threshold=800000

#the class to transform bytes pulled from Kafka into a message object. (deserialization)
transformer.class=cn.edu.ruc.iir.paraflow.examples.loader.TpchDataTransformer

#ON_HEAP segments storage directory
memory.warehouse=file:///dev/shm/paraflow/

#ON_DISK segments storage directory
hdfs.warehouse=hdfs://dbiir01:9000/paraflow/

# Kafka consumer
bootstrap.servers=dbiir02:9192,dbiir03:9193,dbiir04:9194,dbiir05:9195,dbiir06:9196,dbiir07:9197,dbiir08:9198
group.id=paraflow
enable.auto.commit=false
auto.commit.interval.ms=1000
max.poll.interval.ms=5000
max.poll.records=500000

# Meta server
meta.server.host=10.77.110.11
meta.server.port=10012
meta.client.shutdown.timeout=2

# Orc
orc.file.stripe.size=67108864
orc.file.buffer.size=131072
orc.file.block.size=134217728

# Parquet
parquet.compression.codec=snappy
#block size: 256MB
parquet.block.size=268435456
#page size: 1MB
parquet.page.size=1048576
#dictionary page size: 1MB
parquet.dictionary.page.size=1048576
parquet.dictionary.enable=true
parquet.validating=true
# PushGateWay
metric.enabled=false
gateway.url=dbiir00:9101
